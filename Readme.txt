****************************************************************************************************************************************************************************************
Основна папка програми - dist
В папці addition - знаходяться текстові файли зі стоп словами та текстовий файл for file в якому пояснення до 
створеної таблиця програмою CalculateCorpusData.
Для старту роботи програми відкриваємо папку dist та запускаємо mergen_script.exe
В цьому .exe файлі у нас знаходяться 3 підпрограми(3 кроки для створення таблиця слів за оцінкою TF-IDF):

1 підпрограма - PreProcessingApp - займається обробкою бази текстів для подальшого використання іншою програмою
Підпункти підпрограми:
Select stop list file - Завантажуємо текстовий файл зі стоп словами який розташований в папці addition
Select source folder - Обираємо папку з нашою базою текстів
Select target folder - Обираємо куда записати тексти які пройшли препроцесинг
Select language - Обираємо мову текстів
Select stop word mode - Обираємо дію зі стоп словами які зустрінуться в нашій базі текстів : 
	Remove - видалити,
	Replace - замінити, 
	Asls - залишити в тексті.
Replace stop word as - Якщо в пункті Select stop word mode обрати Replace то в цьому пункті ми вводимо на яке слово замінити стоп слово
Select processing mode - обираємо як перетворювати слова в різних відмінках до якогось одного слова.
	Stemmer – Залишає зі слова тільки основу
	Lemmatize – Зводить слова в різних відмінках до називного
	Asls – Залишає слова в іхньому вигляді
Select sentenct terminator mode -Дія з символами типу (.?!) 
	Remove – Видаляє ці символи,
	Replace – Заміню їх на символи шо вказані в рядку Replace sentence terminators(.!?) as:
Select cipher(0-9) mode - Дія з цифрами : Asls - Залишає їх, Remove видаляє

2 підпрограма - CalculateCorpusData - працює з базою текстів яка пройшла через препроцесинг та створює з усіх текстів таблицю усіх слів з нашою бази
і певним коефіцієнтом навпроти.На вхід програми ми подаємо папку з очищеною базою текстів і на виході отримуємо
2 файли записані в папку \dist\Result_of_Corpus_Data розширення .csv  _info та _dict, в _info міститься коротка інформація по базі текстів
а в _dict міститься таблиця слів з певним коефіцієнтом навпроти:
	Колонка A - Слово
	Колонка B - Sum F (Абсолютна частота)
	Колонка С – f (Середня частота)
	Колонка D - fw (середнє зважене)
	Колонка E - nt (к-сть документів, де трапилось слово)
	Колонка F - sigma ( сер.кв.відхилення)
	Колонка G - sigmaw (сер. кв. відх. на основі fw)
	Колонка H - Sum (F^2 / L)
	Колонка I - Sum (F^2 / L^2)

3 підпрограма - CalculateKeynessRelative_AddDictTextToIndex в неї на вхід ми завантажуємо отримані з 2 підпрограми файли _info та _dict та певний очищений текст з нашої бази
і на виході в папці \dist\Result_of_Keyness_Relative отримуємо таблиці оцінки слів різними методами включно TF-IDF
	Колонка A – Ранг слова
	Колонка B - Слово
	Колонка С – Оцінка слова
	Колонка D – Нормована оцінка слова
	Колонка E – Абсолютна частота
	Колонка F – Відносна частота

**********************************************************************************************************************************************************




